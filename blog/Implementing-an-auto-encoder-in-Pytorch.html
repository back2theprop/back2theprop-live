<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Implementing an Autoencoder in Pytorch</title>
<meta name="generator" content="Jekyll v4.2.0">
<meta property="og:title" content="Implementing an Autoencoder in Pytorch">
<meta name="author" content="Ahmad">
<meta property="og:locale" content="en">
<meta name="description" content="Imports and Setup">
<meta property="og:description" content="Imports and Setup">
<link rel="canonical" href="https://back2theprop.com/blog/Implementing-an-auto-encoder-in-Pytorch">
<meta property="og:url" content="https://back2theprop.com/blog/Implementing-an-auto-encoder-in-Pytorch">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2021-05-14T00:00:00+03:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Implementing an Autoencoder in Pytorch">
<script type="application/ld+json">
{"@type":"BlogPosting","url":"https://back2theprop.com/blog/Implementing-an-auto-encoder-in-Pytorch","headline":"Implementing an Autoencoder in Pytorch","dateModified":"2021-05-14T00:00:00+03:00","datePublished":"2021-05-14T00:00:00+03:00","author":{"@type":"Person","name":"Ahmad"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://back2theprop.com/blog/Implementing-an-auto-encoder-in-Pytorch"},"description":"Imports and Setup","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="shortcut icon" href="/favicon.png">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <script src="/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="https://back2theprop.com/feed.xml">
<!---->
<!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-82E6YNM8MY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-82E6YNM8MY');
  </script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js"></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
</head>
<body>



















<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/">
  <img class="site-favicon" title="" src="/favicon.png" onerror="this.style.display='none'">
  
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">
<a class="page-link" href="/">BACK TO THE PROP</a><a class="page-link" href="/archives">ARCHIVES</a><a class="page-link" href="/categories">CATEGORIES</a><a class="page-link" href="/about">ABOUT</a>




<span class="page-link">

<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: '',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  (function() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  })();
</script>











































  <section class="page-banner">
    <div class="page-banner-img">
      <div style="background-image: url(https://images.pexels.com/photos/7319074/pexels-photo-7319074.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260)"></div>
    </div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">Implementing an Autoencoder in Pytorch</h1>
  <h3 class="post-subtitle">A straight forward guide to coding up an autoencoder in pytorch and training it on the MNIST dataset.</h3>

  <p class="post-meta">
    <time class="dt-published" datetime="2021-05-14T00:00:00+03:00" itemprop="datePublished"><i class="fa fa-calendar"></i> May 14, 2021
    </time>

    
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 14 mins</span>
  </p>
<div class="post-tags">
<a class="post-tag" href="/tags.html#autoencoder,">#autoencoder,</a><a class="post-tag" href="/tags.html#supervised">#supervised</a><a class="post-tag" href="/tags.html#learning">#learning</a>
</div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">‚òÄÔ∏è</p>
      <p class="dark">üåë</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('auto' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="imports-and-setup">Imports and Setup</h2>

<p>In this blog post we‚Äôll build an autoencoder in Pytorch from scratch, and have you encoding and decoding your first images! Hop over to <a href="https://colab.research.google.com/notebooks/intro.ipynb#recent=true">google colab</a> and open a blank notebook. To begin, we‚Äôll want to install pytorch and torchvision, since we‚Äôll rely on them for the components that make up our dataset. To install them into our colab notebook:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span>
</code></pre></div></div>

<p>And then we also need to import them:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span><span class="p">,</span> <span class="n">torchvision</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
</code></pre></div></div>

<h2 id="constructing-encoder-and-decoder">Constructing Encoder and Decoder</h2>

<p>Creating the network is also relatively easy, we create two classes, one that represents the encoder and another that represents the decoder. These classes need to a have a very specific format and should always inherit the nn.Module base class. Inheriting from the nn.Module class will automatically give our class some useful and essential properties.</p>

<p>In python, to inherit in from another class we simply pass the class name into the parenthesis of the class that we‚Äôre creating and calling the super() function in the constructor, such as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>
<p>The two other things that are noteworthy here are the layer attribute that we‚Äôre creating and the forward function. Creating a class and making it inherit from nn.Module is only half the work, we also need to declare the number of layers and what kind of layers our network will have. In the case of the simple encoder, we are just going to create a single fully connected layer, that can take as input some tensor of a specific shape and outputs another tensor with a different shape. In our case we‚Äôre creating a layer that takes as input a tensor with 784 dimensions and outputs a tensor with 16 dimensions.</p>

<p>Next up is the forward method. The forward method specifies how our neural network is connected, or ‚Äòwired‚Äô internally if you will. You can imagine the input to the forward method as the input to our neural network, here the input is designated by the variable ‚Äòx‚Äô. x is then immediately passed as an input to the layer that we declared in our constructor, this means that we‚Äôre passing it through that layer and receive the output of that layer in x again, and we return it. Whatever we return from the forward method, will be the output of our neural network.</p>

<p>We rinse and repeat the same steps for the decoder, except that the layer in the decoder has the input and output shapes reversed. This essentially means that we‚Äôre creating two separate neural networks, one that is the encoder and another that is the decoder.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<h2 id="chaining-encoder-and-decoder-together">Chaining Encoder and Decoder Together</h2>

<p>Now we have two separate nets that should ultimately comprise our entire pipeline, in this manner we need to chain them together. We can do this by creating a 3rd class, that also inherits nn.Module, and which holds two member variables, that are instances of the Encoder and Decoder that we just created. This showcases the amazing modularity of pytorch, which allows us to integrate one network as a part of another network. You can also see the forward function, which again as before will pass the input x through the encoder, pass it on to the decoder and then ultimately output it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<h2 id="training-setup">Training Setup</h2>
<p>We‚Äôve created and wired our network, now we still need to set up some stuff before we can begin training. Ideally we want to train on a GPU to accelerate this process, and since we‚Äôre on google colab, we can run our model on the provided GPU with following statements:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#  use gpu if available
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>

<span class="c1"># create a model from `AE` autoencoder class
# load it to the specified device, either gpu or cpu
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AE</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Next up we need to specify an optimizer and a criterion. The optimizer is the procedure by which we improve our neural network during training, the criterion is the metric that calculates how well or how badly we performed each training step. We‚Äôll utilize the most standard optimizer and criterion, which are the Adam optimizer and the Mean Square Error Loss:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create an optimizer object
# Adam optimizer with learning rate 1e-3
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># mean-squared error loss
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
</code></pre></div></div>

<p>The mean square error loss essentially compares the pixel values of the output to those of the input.</p>

<h2 id="preparing-the-dataset">Preparing the Dataset</h2>

<p>To train our network we also still need some data. We‚Äôll train our dataset on the good old MNIST dataset that consists of greyscale images of handwritten digits that are 28x28 in dimension. Downloading it is also straightforward,</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">()])</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s">"~/torch_datasets"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s">"~/torch_datasets"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div>
<p>You can see that we‚Äôre actually downloading two datasets, one for training and another for testing. We also need to declare two data loaders, which will allow us to conveniently feed our dataset to our network:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span>
<span class="p">)</span>
</code></pre></div></div>
<h2 id="the-training-loop">The training Loop</h2>

<p>Now we‚Äôve completed all the setup and can start training. The training loop is the most integral component of our code and we‚Äôll go through it step by step. Firstly, we‚Äôll create a main loop that will specify the number of epochs that we‚Äôll train for. Every epoch our network will see the entire dataset, not all at once, but rather in small portions. The small portions are called batches. This is where the data-loaders, that we previously created, come into play. We create a loop statement that gets a batch of ‚Äòfeatures‚Äô (input images), to pass to the auto encoder.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1">#training loop steps go here
</span></code></pre></div></div>

<p>These batches of data need to be flattened such that they have the exact shape that we specified earlier when we constructed our encoder layer. In this manner we flatten the 28x28 pixel images into a linear tensor of 784 dimensions. We can do this with the view() function in pytorch. We also need to make sure that we send this batch of data to device that we‚Äôre training on (GPU, same as network):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># reshape mini-batch data to [N, 784] matrix
# load it to the active device
</span><span class="n">batch_features</span> <span class="o">=</span> <span class="n">batch_features</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Another important function call that should generally be made before we feed the batch to our network, depending on the type of neural network you‚Äôre training and what you‚Äôre trying to achieve, is ‚Äòzero_grad()‚Äô on the optimizer. This function call resets the gradients to zero before backpropagation. Otherwise we would be accumulating the gradients, which is useful when training RNNs for example.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># reset the gradients back to zero
# PyTorch accumulates gradients on subsequent backward passes
</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div></div>

<p>Next, we pass the batch to our network such that we perform a forward pass, and receive what comes out on the other end in the outputs variable. After that we need to obtain the training loss by comparing input and outputs with our specified criterion. Note that train_loss here, is not just a number but rather a tensor that has functionality:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute reconstructions
</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_features</span><span class="p">)</span>

<span class="c1"># compute training reconstruction loss
</span><span class="n">train_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">)</span>
</code></pre></div></div>

<p>After obtaining the training loss for a specific batch, we perform backpropagation and perform an optimizer step.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute accumulated gradients
</span><span class="n">train_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># perform parameter update based on current gradients
</span><span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<p>We also have a variable that accumulates the loss over every batch, which we then average outside the inner loop and print to screen to verify that the network is improving and that the overall loss is decreasing:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1"># add the mini-batch training loss to epoch loss
</span>    <span class="n">loss</span> <span class="o">+=</span> <span class="n">train_loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1">### Outside the batch loop ###
# compute the epoch training loss
</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

<span class="c1"># display the epoch training loss
</span><span class="k">print</span><span class="p">(</span><span class="s">"epoch : {}/{}, loss = {:.6f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
</code></pre></div></div>

<p>The training loop in it‚Äôs entirety will look like this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># reshape mini-batch data to [N, 784] matrix
</span>        <span class="c1"># load it to the active device
</span>        <span class="n">batch_features</span> <span class="o">=</span> <span class="n">batch_features</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># reset the gradients back to zero
</span>        <span class="c1"># PyTorch accumulates gradients on subsequent backward passes
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># compute reconstructions
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_features</span><span class="p">)</span>

        <span class="c1"># compute training reconstruction loss
</span>        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">)</span>

        <span class="c1"># compute accumulated gradients
</span>        <span class="n">train_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># perform parameter update based on current gradients
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># add the mini-batch training loss to epoch loss
</span>        <span class="n">loss</span> <span class="o">+=</span> <span class="n">train_loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># compute the epoch training loss
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

    <span class="c1"># display the epoch training loss
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"epoch : {}/{}, loss = {:.6f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="testing-the-model">Testing the model</h2>

<p>Lastly, we also want to see how well our model performs qualitatively, we can do this by looking at some of the outputs that our model outputs and compare them with the original input. We‚Äôll need to import the matplotlib library for that and use our test_loader, which holds data that was not included in the training dataset. This will give us a good idea how well our model can generalize to new data:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">batch_features</span> <span class="o">=</span> <span class="n">batch_features</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_features</span><span class="p">)</span>
    <span class="c1">#print(outputs.shape)
</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'IMAGE'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">batch_features</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span>


    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>        
</code></pre></div></div>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/blog/Origins-of-the-autoencoder" title="Origins of the Autoencoder">Origins of the Autoencoder</a><a class="next" href="/blog/Audio-Data-Fourier-Transform-and-Spectrograms" title="Audio Data, Fourier Transform and Spectrograms">Audio Data, Fourier Transform and Spectrograms...</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li><a class="post-link" href="/blog/Implementing-a-Convolutional-classifier-in-pytorch-for-CIFAR10-Copy" title="Audio Data, Fourier Transform and Spectrograms">Implementing a convolutional classifier in pytorch for CIFAR10</a></li>
<li><a class="post-link" href="/blog/Audio-Data-Fourier-Transform-and-Spectrograms" title="Audio Data, Fourier Transform and Spectrograms">Audio Data, Fourier Transform and Spectrograms</a></li>
<li><a class="post-link" href="/blog/A-guide-to-pre-processing-spectrograms" title="Audio Data, Fourier Transform and Spectrograms">A guide to pre-processing Spectrograms</a></li>
<li><a class="post-link" href="/blog/Implementing-an-auto-encoder-in-Pytorch" title="Audio Data, Fourier Transform and Spectrograms">Implementing an Autoencoder in Pytorch</a></li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">Quick Links</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
      <div>Copyright ¬© 2020-2021 @Wiem Ben Rim &amp; Ahmad Moussa</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="http://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
</html>
